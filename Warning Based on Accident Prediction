import cv2
import numpy as np
import time
import torch
import math
from ultralytics import YOLO
import torchvision.transforms as transforms
from PIL import Image
# (DeepSORT import is provided if you want to switch to a robust tracker later)
#from deep_sort_realtime.deepsort_tracker import DeepSort

# -------------------------
# Load Models
# -------------------------
# YOLOv8 for object detection
model = YOLO("yolov8n.pt")  # Will download weights if not present

# MiDaS for depth estimation
midas = torch.hub.load("intel-isl/MiDaS", "MiDaS_small")
midas.eval()

# Transformation for MiDaS input (expects a PIL image)
transform = transforms.Compose([
    transforms.Resize((384, 384)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# -------------------------
# Setup Video Capture (Webcam)
# -------------------------
video = cv2.VideoCapture(0)
if not video.isOpened():
    print("Error: Could not open webcam.")
    exit()

# -------------------------
# Simple Centroid Tracking Setup
# -------------------------
tracked_objects = {}  # Mapping object ID -> (center_x, center_y, distance, timestamp)
next_object_id = 0
match_threshold = 50  # Pixel threshold for matching detections

# -------------------------
# Calibration & Collision Warning Thresholds
# -------------------------
scale_factor = 25         # Factor to convert MiDaS relative depth to meters (calibrate this)
distance_threshold = 7    # Danger if object is closer than 7 meters
speed_threshold = 3       # Danger if speed exceeds 3 m/s

# -------------------------
# Frame Skipping Parameters for FPS Improvement
# -------------------------
detection_update_interval = 2  # Run YOLO detection every 2 frames
depth_update_interval = 3      # Run depth estimation every 3 frames

frame_count = 0
cached_detections = None
cached_depth_map = None

while True:
    ret, frame = video.read()
    if not ret:
        break

    frame_count += 1
    current_time = time.time()
    frame_height, frame_width = frame.shape[:2]

    # -------------------------
    # YOLO Detection (with caching)
    # -------------------------
    if frame_count % detection_update_interval == 0 or cached_detections is None:
        results = model(frame)
        cached_detections = results[0]  # Get the first result object
    detection_result = cached_detections

    # -------------------------
    # Depth Estimation (with caching)
    # -------------------------
    if frame_count % depth_update_interval == 0 or cached_depth_map is None:
        frame_resized = cv2.resize(frame, (384, 384))
        # Convert BGR to RGB and then to PIL image
        frame_pil = Image.fromarray(cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB))
        input_tensor = transform(frame_pil).unsqueeze(0)
        with torch.no_grad():
            depth_map = midas(input_tensor).squeeze().numpy()
        # Normalize depth map to [0, 1]
        depth_map = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min())
        cached_depth_map = depth_map.copy()
    else:
        depth_map = cached_depth_map

    # Scaling factors to convert coordinates from full frame to MiDaS resolution (384x384)
    scale_x = 384 / frame_width
    scale_y = 384 / frame_height

    # -------------------------
    # Define Fixed ROI (diagonal line) - (optional: can be used with other logic)
    # -------------------------
    # (This example does not integrate ROI-checking for collision but can be added if needed)

    # -------------------------
    # Process Each Detection and Track Objects
    # -------------------------
    # Variables to hold the nearest object in the danger zone
    near_flag = False
    near_distance = float('inf')
    near_speed = 0

    if detection_result is not None:
        for idx, box in enumerate(detection_result.boxes.xyxy):
            data = box.cpu().numpy()
            if data.shape[0] != 4:
                continue
            x1, y1, x2, y2 = data

            # Get detection confidence (if available)
            if hasattr(detection_result.boxes, 'conf') and len(detection_result.boxes.conf) > idx:
                conf = float(detection_result.boxes.conf[idx])
            else:
                conf = 1.0
            if conf < 0.3:
                continue

            # Filter by bounding box area
            area = (x2 - x1) * (y2 - y1)
            if area < 500:
                continue

            # Compute center of bounding box
            center_x = int((x1 + x2) / 2)
            center_y = int((y1 + y2) / 2)

            # Map center coordinates to depth map coordinates
            d_x = int(center_x * scale_x)
            d_y = int(center_y * scale_y)
            d_x = np.clip(d_x, 0, 383)
            d_y = np.clip(d_y, 0, 383)
            raw_depth = depth_map[d_y, d_x]
            distance = raw_depth * scale_factor  # Approximate distance in meters

            # -------------------------
            # Simple Centroid-Based Tracking
            # -------------------------
            assigned_id = None
            min_euclidean = float("inf")
            for obj_id, (prev_x, prev_y, prev_distance, prev_time) in tracked_objects.items():
                euclidean_dist = math.hypot(center_x - prev_x, center_y - prev_y)
                if euclidean_dist < match_threshold and euclidean_dist < min_euclidean:
                    min_euclidean = euclidean_dist
                    assigned_id = obj_id

            if assigned_id is None:
                assigned_id = next_object_id
                next_object_id += 1
                speed = 0
            else:
                prev_x, prev_y, prev_distance, prev_time = tracked_objects[assigned_id]
                dt = current_time - prev_time if (current_time - prev_time) > 0 else 1e-6
                speed = abs(distance - prev_distance) / dt  # m/s

            tracked_objects[assigned_id] = (center_x, center_y, distance, current_time)
            print(f"Object ID {assigned_id}: Distance = {distance:.2f} m, Speed = {speed:.2f} m/s")

            # Check if the object is "near" the monitor (danger zone)
            if distance < distance_threshold:
                near_flag = True
                if distance < near_distance:
                    near_distance = distance
                    near_speed = speed

            # Draw bounding box and info on each object (green by default)
            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
            cv2.putText(frame, f"ID:{assigned_id} {distance:.2f}m", (int(x1), int(y1) - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
            cv2.putText(frame, f"{speed:.2f}m/s", (int(x1), int(y2) + 20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

    # -------------------------
    # Overlay Warning if an object is near
    # -------------------------
    if near_flag:
        warning_text = f"WARNING: Near! Speed: {near_speed:.2f} m/s, Dist: {near_distance:.2f} m"
        cv2.putText(frame, warning_text, (50, 100),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)

    # -------------------------
    # Display the annotated frame
    # -------------------------
    cv2.imshow("Accident Prediction System", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

video.release()
cv2.destroyAllWindows()
